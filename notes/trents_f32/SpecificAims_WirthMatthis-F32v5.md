**Specific Aims**

Successful human locomotion over complex terrain relies on robust
communication between the visual and motor systems. Investigations into
recently accumulated datasets of *visuo-locomotor* behavior in complex
natural environments demonstrates that visual search might be influenced
by biomechanical information, such as where the efficient locomotor
system^1,13,14^ would *want* to step; but this hypothesis has never been
empirically tested. Investigating the influence of biomechanics in
visual search for footholds is critical for developing our knowledge of
human mobility, providing a basic-science understanding for some of the
most common challenges to the activities of daily living, such the
navigation of a cluttered home, and how this everyday problem is
complicated by visual^3^ and motor diseases.

Classic study of the biomechanics of locomotion consistently
demonstrates that human locomotion is energetically efficient^1,13^.
Recent empirical insights provide evidence that humans are constantly
adapting their gait -- re-converging on energetically efficient
movements within seconds of perturbation^14^. Visual search for targets
in natural scene statistics is accurately predicted by an ideal observer
model^6^, where eye movements are made to maximize the probability of
finding the target. Additionally, the study of eye movements in natural
environments shows that visual search is also highly
task-dependent^5,7--11^, suggesting that the visual system works to
provide information relevant to the current goals of the perceiver.
Necessarily, then, the visual system must be seeking information which
allows for energetically preferable movements through the natural world
-- but there has yet to be scientific investigation into how
biomechanical information might influence visual search. [In this
proposal, it is our goal to determine the influence of biomechanics on
visual search for footholds.]{.underline} Here, we develop a novel
paradigm where subjects will actively walk across a 14x3m Augmented
Reality projector display, providing the first empirical method
sufficient to fulfill the aims proposed.

Fulfillment of this proposal requires a team of expert interdisciplinary
mentors, which is precisely why I have chosen Dr. Jonathan Matthis, Dr.
Peter Bex, and Dr. Dagmar Sternad as my sponsors and co-sponsors,
respectively. Dr. Matthis is one of the few world experts trained in
measuring eye movements during natural terrain traversal. Combining Dr.
Matthis' unique expertise with the training I will receive from my
co-sponsors in psychophysics (Dr. Bex) and motor control (Dr. Sternad),
I will be fully equipped to achieve the aims proposed. With their joint
guidance, I will build upon my expertise of exploring complex systems
and apply it to the problem of parameterizing the visuo-locomotor
system, providing myself the foundation for a competitive K-99
application.

**[Aim 1: Manipulate task-constraints to investigate visual search
strategies in pure-visual vs. locomotor-constrained visual search tasks,
with and without self-motion.]{.underline}**

In **Experiment 1*, ***we test the hypothesis that visual search
strategies will take a different shape when searching the same
groundplane stimulus, for targets circles among distractor Landolt C's
in three different tasks: While standing still (Condition 1 --
biomechanics *independent*) vs. While searching for targets while
walking (Condition 2 -- self-motion without specified biomechanical
constraints) vs. While searching for target-footholds (Condition 3 --
biomechanics *dependent*). We predict that the participant's next
preferred foothold (calculated based off of a dynamic walking model^1^)
will influence the visual search pattern in condition 3, but not
conditions 1 and 2. Thus, fixations should fall near estimated
biomechanically preferred footholds in condition 3, but not conditions 1
and 2, even if that means fixating on otherwise non-salient spaces in
the terrain.

[**Aim 2:** **Measure the relationship between visual search difficulty
and biomechanically informed route planning strategies.**]{.underline}

In **Experiment 2**, participants are tasked with walking across the
14x3m Augmented Reality projector display while stepping on only circles
and avoiding C's. We increase the visual search difficulty by increasing
visual acuity of the distractor "C" (decreasing the size in the "C"
gap). We predict that as visual acuity increases, that the visual search
pattern stretch further out spatiotemporally, reflecting a greater need
for step-planning certainty. We test this by measuring the distance
between fixations and the nearest upcoming foothold (identified in
post-processing), as well as the relationship between acuity and walking
speed.

**[Aim 3: *Observe the visuo-locomotor system in natural, unconstrained
environments *]{.underline}**

In **Experiment 3**, we test the generalizability of aims 1 and 2 by
measuring the influence of biomechanical information in natural, outdoor
terrains. Using new 3-D terrain mapping, in combination with tetherless
IMU based motion capture and binocular eye-tracking, we will be able to
measure the visuo-locomotor system in unprecedented detail.
