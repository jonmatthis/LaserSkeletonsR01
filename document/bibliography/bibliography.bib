
@article{lappe1993,
	title = {A Neural Network for the Processing of Optic Flow from Ego-Motion in Man and Higher Mammals},
	volume = {5},
	issn = {0899-7667, 1530-888X},
	url = {https://www.mitpressjournals.org/doi/abs/10.1162/neco.1993.5.3.374},
	doi = {10.1162/neco.1993.5.3.374},
	abstract = {Interest in the processing of optic flow has increased recently in both the neurophysiological and the psychophysical communities. We have designed a neural network model of the visual motion pathway in higher mammals that detects the direction of heading from optic flow. The model is a neural implementation of the subspace algorithm introduced by Heeger and Jepson (1990). We have tested the network in simulations that are closely related to psychophysical and neurophysiological experiments and show that our results are consistent with recent data from both fields. The network reproduces some key properties of human ego-motion perception. At the same time, it produces neurons that are selective for different components of ego-motion flow fields, such as expansions and rotations. These properties are reminiscent of a subclass of neurons in cortical area {MSTd}, the triple-component neurons. We propose that the output of such neurons could be used to generate a computational map of heading directions in or beyond {MST}.},
	pages = {374--391},
	number = {3},
	journaltitle = {Neural Computation},
	shortjournal = {Neural Computation},
	author = {Lappe, Markus and Rauschecker, Josef P.},
	urldate = {2021-01-27},
	date = {1993-05},
	langid = {english},
}

@article{wang1999,
	title = {A Probabilistic Model for Recovering Camera Translation},
	volume = {76},
	issn = {10773142},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1077314299907981},
	doi = {10.1006/cviu.1999.0798},
	pages = {205--212},
	number = {3},
	journaltitle = {Computer Vision and Image Understanding},
	shortjournal = {Computer Vision and Image Understanding},
	author = {Wang, Ranxiao Frances and Cutting, James E.},
	urldate = {2021-01-26},
	date = {1999-12},
	langid = {english},
}

@article{Menz2003,
	title = {Acceleration patterns of the head and pelvis when walking on level and irregular surfaces},
	volume = {18},
	issn = {09666362},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0966636202001595},
	doi = {10.1016/S0966-6362(02)00159-5},
	abstract = {The aim of this study was to evaluate acceleration patterns at the head and pelvis while subjects walked on a level and an irregular walking surface, to develop an understanding of how the postural control system responds to challenging walking conditions. Thirty young, healthy subjects walked on a level corridor and on artificial grass underlain with foam and wooden blocks placed in an arbitrary manner. Temporo-spatial gait parameters and acceleration patterns at the head and pelvis were measured. The results revealed that when walking on the irregular surface, subjects were able to maintain their velocity, but adopted a slower and more variable cadence and a significantly longer stride length. The magnitude of pelvis accelerations increased, however head accelerations were not affected by the walking surface. When considered as an overall pattern of movement, these findings suggest that one of the primary objectives of the postural control system when walking on irregular surfaces is head control, and that subjects adapt their stepping pattern on irregular surfaces to ensure that the head remains stable.},
	pages = {35--46},
	number = {1},
	journaltitle = {Gait \& Posture},
	shortjournal = {Gait \& Posture},
	author = {Menz, Hylton B. and Lord, Stephen R. and Fitzpatrick, Richard C.},
	urldate = {2020-07-20},
	date = {2003-08},
	langid = {english},
}

@article{Kavanagh2008,
	title = {Accelerometry: A technique for quantifying movement patterns during walking},
	volume = {28},
	issn = {09666362},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0966636207002706},
	doi = {10.1016/j.gaitpost.2007.10.010},
	shorttitle = {Accelerometry},
	abstract = {The popularity of using accelerometer-based systems to quantify human movement patterns has increased in recent years for clinicians and researchers alike. The beneﬁts of using accelerometers compared to more traditional gait analysis instruments include low cost; testing is not restricted to a laboratory environment; accelerometers are small, therefore walking is relatively unrestricted; and direct measurement of 3D accelerations eliminate errors associated with differentiating displacement and velocity data. However, accelerometry is not without its disadvantages, an issue which is scarcely reported in gait analysis literature. This paper reviews the use of accelerometer technology to investigate gait-related movement patterns, and addresses issues of acceleration measurement important for experimental design. An overview of accelerometer mechanics is provided before illustrating speciﬁc experimental conditions necessary to ensure the accuracy of gaitrelated acceleration measurement. A literature review is presented on how accelerometry has been used to examine basic temporospatial gait parameters, shock attenuation, and segmental accelerations of the body during walking. The output of accelerometers attached to the upper body has provided useful insights into the motor control of normal walking, age-related differences in dynamic postural control, and gait patterns in people with movement disorders.},
	pages = {1--15},
	number = {1},
	journaltitle = {Gait \& Posture},
	shortjournal = {Gait \& Posture},
	author = {Kavanagh, Justin J. and Menz, Hylton B.},
	urldate = {2020-07-20},
	date = {2008-07},
	langid = {english},
}

@incollection{Warren1988,
	title = {Action Modes and Laws of Control for the Visual Guidance Of Action},
	volume = {50},
	isbn = {978-0-444-70389-7},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0166411508625649},
	pages = {339--379},
	booktitle = {Advances in Psychology},
	publisher = {Elsevier},
	author = {Warren, William H.},
	urldate = {2020-07-18},
	date = {1988},
	langid = {english},
	doi = {10.1016/S0166-4115(08)62564-9},
}

@article{perrone1994,
	title = {A model of self-motion estimation within primate extrastriate visual cortex},
	volume = {34},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0042698994900604},
	doi = {10.1016/0042-6989(94)90060-4},
	pages = {2917--2938},
	number = {21},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Perrone, John A. and Stone, Leland S.},
	urldate = {2021-01-27},
	date = {1994-11},
	langid = {english},
}

@article{layton2016,
	title = {A Neural Model of {MST} and {MT} Explains Perceived Object Motion during Self-Motion},
	volume = {36},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.4593-15.2016},
	doi = {10.1523/JNEUROSCI.4593-15.2016},
	pages = {8093--8102},
	number = {31},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {Journal of Neuroscience},
	author = {Layton, O. W. and Fajen, B. R.},
	urldate = {2021-01-27},
	date = {2016-08-03},
	langid = {english},
}

@article{Finley2014,
	title = {A novel optic flow pattern speeds split-belt locomotor adaptation},
	volume = {111},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.00513.2013},
	doi = {10.1152/jn.00513.2013},
	abstract = {Visual input provides vital information for helping us modify our walking pattern. For example, artificial optic flow can drive changes in step length during locomotion and may also be useful for augmenting locomotor training for individuals with gait asymmetries. Here we asked whether optic flow could modify the acquisition of a symmetric walking pattern during split-belt treadmill adaptation. Participants walked on a split-belt treadmill while watching a virtual scene that produced artificial optic flow. For the Stance Congruent group, the scene moved at the slow belt speed at foot strike on the slow belt and then moved at the fast belt speed at foot strike on the fast belt. This approximates what participants would see if they moved over ground with the same walking pattern. For the Stance Incongruent group, the scene moved fast during slow stance and vice versa. In this case, flow speed does not match what the foot is experiencing, but predicts the belt speed for the next foot strike. Results showed that the Stance Incongruent group learned more quickly than the Stance Congruent group even though each group learned the same amount during adaptation. The increase in learning rate was primarily driven by changes in spatial control of each limb, rather than temporal control. Interestingly, when this alternating optic flow pattern was presented alone, no adaptation occurred. Our results demonstrate that an unnatural pattern of optic flow, one that predicts the belt speed on the next foot strike, can be used to enhance learning rate during split-belt locomotor adaptation.},
	pages = {969--976},
	number = {5},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Finley, James M. and Statton, Matthew A. and Bastian, Amy J.},
	urldate = {2020-07-18},
	date = {2014-03-01},
	langid = {english},
}

@incollection{Warren2007,
	title = {Action-scaled information for the visual control of locomotion},
	pages = {243--258},
	booktitle = {Closing the gap: The scientific writings of David N. Lee},
	publisher = {Erlbaum},
	author = {Warren, William H},
	date = {2007},
}

@article{Cormack2017,
	title = {Binocular Mechanisms of 3D Motion Processing},
	volume = {3},
	issn = {2374-4642, 2374-4650},
	url = {http://www.annualreviews.org/doi/10.1146/annurev-vision-102016-061259},
	doi = {10.1146/annurev-vision-102016-061259},
	pages = {297--318},
	number = {1},
	journaltitle = {Annual Review of Vision Science},
	shortjournal = {Annu. Rev. Vis. Sci.},
	author = {Cormack, Lawrence K. and Czuba, Thaddeus B. and Knöll, Jonas and Huk, Alexander C.},
	urldate = {2020-07-18},
	date = {2017-09-15},
	langid = {english},
}

@article{Evans2012,
	title = {Collecting and Analyzing Eye-tracking Data in Outdoor Environments},
	pages = {19},
	journaltitle = {R. A.},
	author = {Evans, Karen M and Jacobs, Robert A and Tarduno, John A and Pelz, Jeff B},
	date = {2012},
	langid = {english},
}

@article{friedburg2004,
	title = {Contribution of cone photoreceptors and post-receptoral mechanisms to the human photopic electroretinogram: Human cone {ERG}},
	volume = {556},
	issn = {00223751},
	url = {http://doi.wiley.com/10.1113/jphysiol.2004.061523},
	doi = {10.1113/jphysiol.2004.061523},
	shorttitle = {Contribution of cone photoreceptors and post-receptoral mechanisms to the human photopic electroretinogram},
	pages = {819--834},
	number = {3},
	journaltitle = {The Journal of Physiology},
	author = {Friedburg, C. and Allen, C. P. and Mason, P. J. and Lamb, T. D.},
	urldate = {2021-01-26},
	date = {2004-05},
	langid = {english},
}

@article{Zajac2002,
	title = {Biomechanics and muscle coordination of human walking},
	volume = {16},
	issn = {09666362},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0966636202000681},
	doi = {10.1016/S0966-6362(02)00068-1},
	pages = {215--232},
	number = {3},
	journaltitle = {Gait \& Posture},
	shortjournal = {Gait \& Posture},
	author = {Zajac, Felix E. and Neptune, Richard R. and Kautz, Steven A.},
	urldate = {2020-07-18},
	date = {2002-12},
	langid = {english},
}

@inproceedings{Weinzaepfel2013,
	location = {Sydney, Australia},
	title = {{DeepFlow}: Large Displacement Optical Flow with Deep Matching},
	isbn = {978-1-4799-2840-8},
	url = {http://ieeexplore.ieee.org/document/6751282/},
	doi = {10.1109/ICCV.2013.175},
	shorttitle = {{DeepFlow}},
	eventtitle = {2013 {IEEE} International Conference on Computer Vision ({ICCV})},
	pages = {1385--1392},
	booktitle = {2013 {IEEE} International Conference on Computer Vision},
	publisher = {{IEEE}},
	author = {Weinzaepfel, Philippe and Revaud, Jerome and Harchaoui, Zaid and Schmid, Cordelia},
	urldate = {2020-07-18},
	date = {2013-12},
}

@article{OConnor2009,
	title = {Direction-Dependent Control of Balance During Walking and Standing},
	volume = {102},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.00131.2009},
	doi = {10.1152/jn.00131.2009},
	abstract = {Human walking has previously been described as “controlled falling.” Some computational models, however, suggest that gait may also have self-stabilizing aspects requiring little {CNS} control. The fore–aft component of walking may even be passively stable from step to step, whereas lateral motion may be unstable and require motor control for balance, as through active foot placement. If this is the case, walking humans might rely less on integrative sensory feedback, such as vision, for anteroposterior ({AP}) than for mediolateral ({ML}) balance. We tested whether healthy humans ( n = 10) exhibit such direction-dependent control, by applying low-frequency perturbations to the visual field (a projected virtual hallway) and measuring foot placement during treadmill walking. We found step variability to be nearly 10 times more sensitive to {ML} than to {AP} perturbations, as quantified by the increase in root-mean-square step variability per unit change in perturbation amplitude. This is not simply due to poorer physiological sensitivity of vision in the {AP} direction: similar perturbations applied to quiet standing produced reversed direction dependence, with an {AP} sensitivity 2.3-fold greater than that of {ML}. Tandem (heel-to-toe) standing yielded {ML} sensitivity threefold greater than that of {AP}, suggesting that the base of support influences the stability of standing. Postural balance nevertheless appears to require continuous, integrative motor control for balance in all directions. In contrast, walking balance requires step-by-step, integrative control for balance, but mainly in the lateral direction. In the fore–aft direction, balance may be maintained through an “uncontrolled,” yet passively stabilized, series of falls.},
	pages = {1411--1419},
	number = {3},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {O'Connor, Shawn M. and Kuo, Arthur D.},
	urldate = {2020-07-18},
	date = {2009-09},
	langid = {english},
}

@article{calow2008a,
	title = {Efficient encoding of natural optic flow},
	volume = {19},
	issn = {0954-898X, 1361-6536},
	url = {https://www.tandfonline.com/doi/full/10.1080/09548980802368764},
	doi = {10.1080/09548980802368764},
	pages = {183--212},
	number = {3},
	journaltitle = {Network: Computation in Neural Systems},
	shortjournal = {Network: Computation in Neural Systems},
	author = {Calow, Dirk and Lappe, Markus},
	urldate = {2021-01-26},
	date = {2008-01},
	langid = {english},
}

@article{Royden1994,
	title = {Estimating heading during eye movements},
	volume = {34},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0042698994900841},
	doi = {10.1016/0042-6989(94)90084-1},
	pages = {3197--3214},
	number = {23},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Royden, Constance S. and Crowell, James A. and Banks, Martin S.},
	urldate = {2020-07-18},
	date = {1994-12},
	langid = {english},
}

@article{Chen2016,
	title = {Evidence for a Causal Contribution of Macaque Vestibular, But Not Intraparietal, Cortex to Heading Perception},
	volume = {36},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/lookup/doi/10.1523/JNEUROSCI.2485-15.2016},
	doi = {10.1523/JNEUROSCI.2485-15.2016},
	pages = {3789--3798},
	number = {13},
	journaltitle = {The Journal of Neuroscience},
	shortjournal = {J. Neurosci.},
	author = {Chen, Aihua and Gu, Yong and Liu, Sheng and {DeAngelis}, Gregory C. and Angelaki, Dora E.},
	urldate = {2020-07-18},
	date = {2016-03-30},
	langid = {english},
}

@article{Warren1990,
	title = {Eye movements and optical flow},
	volume = {7},
	issn = {1084-7529, 1520-8532},
	url = {https://www.osapublishing.org/abstract.cfm?URI=josaa-7-1-160},
	doi = {10.1364/JOSAA.7.000160},
	pages = {160},
	number = {1},
	journaltitle = {Journal of the Optical Society of America A},
	shortjournal = {J. Opt. Soc. Am. A},
	author = {Warren, William H. and Hannon, Danial J.},
	urldate = {2020-07-18},
	date = {1990-01-01},
	langid = {english},
}

@article{Lappi2016,
	title = {Eye movements in the wild: Oculomotor control, gaze behavior \& frames of reference},
	volume = {69},
	issn = {01497634},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0149763415301317},
	doi = {10.1016/j.neubiorev.2016.06.006},
	shorttitle = {Eye movements in the wild},
	pages = {49--68},
	journaltitle = {Neuroscience \& Biobehavioral Reviews},
	shortjournal = {Neuroscience \& Biobehavioral Reviews},
	author = {Lappi, Otto},
	urldate = {2020-07-18},
	date = {2016-10},
	langid = {english},
}

@article{grigo1999,
	title = {Dynamical use of different sources of information in heading judgments from retinal flow},
	volume = {16},
	issn = {1084-7529, 1520-8532},
	url = {https://www.osapublishing.org/abstract.cfm?URI=josaa-16-9-2079},
	doi = {10.1364/JOSAA.16.002079},
	pages = {2079},
	number = {9},
	journaltitle = {Journal of the Optical Society of America A},
	shortjournal = {J. Opt. Soc. Am. A},
	author = {Grigo, Antje and Lappe, Markus},
	urldate = {2021-01-27},
	date = {1999-09-01},
	langid = {english},
}

@article{Chen2013,
	title = {Eye-Centered Representation of Optic Flow Tuning in the Ventral Intraparietal Area},
	volume = {33},
	issn = {0270-6474, 1529-2401},
	url = {http://www.jneurosci.org/cgi/doi/10.1523/JNEUROSCI.2837-13.2013},
	doi = {10.1523/JNEUROSCI.2837-13.2013},
	pages = {18574--18582},
	number = {47},
	journaltitle = {Journal of Neuroscience},
	shortjournal = {Journal of Neuroscience},
	author = {Chen, X. and {DeAngelis}, G. C. and Angelaki, D. E.},
	urldate = {2020-07-18},
	date = {2013-11-20},
	langid = {english},
}

@article{OConnor2012,
	title = {Fast visual prediction and slow optimization of preferred walking speed},
	volume = {107},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.00866.2011},
	doi = {10.1152/jn.00866.2011},
	abstract = {People prefer walking speeds that minimize energetic cost. This may be accomplished by directly sensing metabolic rate and adapting gait to minimize it, but only slowly due to the compounded effects of sensing delays and iterative convergence. Visual and other sensory information is available more rapidly and could help predict which gait changes reduce energetic cost, but only approximately because it relies on prior experience and an indirect means to achieve economy. We used virtual reality to manipulate visually presented speed while 10 healthy subjects freely walked on a self-paced treadmill to test whether the nervous system beneficially combines these two mechanisms. Rather than manipulating the speed of visual flow directly, we coupled it to the walking speed selected by the subject and then manipulated the ratio between these two speeds. We then quantified the dynamics of walking speed adjustments in response to perturbations of the visual speed. For step changes in visual speed, subjects responded with rapid speed adjustments (lasting {\textless}2 s) and in a direction opposite to the perturbation and consistent with returning the visually presented speed toward their preferred walking speed, when visual speed was suddenly twice (one-half) the walking speed, subjects decreased (increased) their speed. Subjects did not maintain the new speed but instead gradually returned toward the speed preferred before the perturbation (lasting {\textgreater}300 s). The timing and direction of these responses strongly indicate that a rapid predictive process informed by visual feedback helps select preferred speed, perhaps to complement a slower optimization process that seeks to minimize energetic cost.},
	pages = {2549--2559},
	number = {9},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {O'Connor, Shawn M. and Donelan, J. Maxwell},
	urldate = {2020-07-18},
	date = {2012-05-01},
	langid = {english},
}

@article{Glennerster2001,
	title = {Fixation could simplify, not complicate, the interpretation of retinal flow},
	volume = {41},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S004269890000300X},
	doi = {10.1016/S0042-6989(00)00300-X},
	pages = {815--834},
	number = {6},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Glennerster, Andrew and Hansard, Miles E. and Fitzgibbon, Andrew W.},
	urldate = {2020-07-18},
	date = {2001-03},
	langid = {english},
}

@article{Matthis2018,
	title = {Gaze and the Control of Foot Placement When Walking in Natural Terrain},
	volume = {28},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982218303099},
	doi = {10.1016/j.cub.2018.03.008},
	pages = {1224--1233.e5},
	number = {8},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Matthis, Jonathan Samir and Yates, Jacob L. and Hayhoe, Mary M.},
	urldate = {2020-07-18},
	date = {2018-04},
	langid = {english},
}

@article{Palmisano2000,
	title = {Global-Perspective Jitter Improves Vection in Central Vision},
	volume = {29},
	issn = {0301-0066, 1468-4233},
	url = {http://journals.sagepub.com/doi/10.1068/p2990},
	doi = {10.1068/p2990},
	abstract = {Previous vection research has tended to minimise visual - vestibular conflict by using optic-flow patterns which simulate self-motions of constant velocity. Here, experiments are reported on the effect of adding 'global-perspective jitter' to these displays -- simulating forward motion of the observer on a platform oscillating in horizontal and/or vertical dimensions. Unlike non-jittering displays, jittering displays produced a situation of sustained visual - vestibular conflict. Contrary to the prevailing notion that visual vestibular conflict impairs vection, jittering optic flow was found to produce shorter vection onsets and longer vection durations than non-jittering optic flow for all of jitter magnitudes and temporal frequencies examined. On the basis of these findings, it would appear that purely radial patterns of optic flow are not the optimal inducing stimuli for vection. Rather, flow patterns which contain both regular and randomoscillating components appear to produce the most compelling subjective experiences of self-motion.},
	pages = {57--67},
	number = {1},
	journaltitle = {Perception},
	shortjournal = {Perception},
	author = {Palmisano, Stephen and Gillam, Barbara J and Blackburn, Shane G},
	urldate = {2020-07-20},
	date = {2000-01},
	langid = {english},
}

@article{Rushton1998,
	title = {Guidance of locomotion on foot uses perceived target location rather than optic flow},
	volume = {8},
	issn = {09609822},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0960982207004927},
	doi = {10.1016/S0960-9822(07)00492-7},
	pages = {1191--1194},
	number = {21},
	journaltitle = {Current Biology},
	shortjournal = {Current Biology},
	author = {Rushton, Simon K. and Harris, Julie M. and Lloyd, Maugan R. and Wann, John P.},
	urldate = {2020-07-20},
	date = {1998-10},
	langid = {english},
}

@article{burlingham2020,
	title = {Heading perception depends on time-varying evolution of optic flow},
	volume = {117},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.2022984117},
	doi = {10.1073/pnas.2022984117},
	abstract = {There is considerable support for the hypothesis that perception of heading in the presence of rotation is mediated by instantaneous optic flow. This hypothesis, however, has never been tested. We introduce a method, termed “nonvarying phase motion,” for generating a stimulus that conveys a single instantaneous optic flow field, even though the stimulus is presented for an extended period of time. In this experiment, observers viewed stimulus videos and performed a forced-choice heading discrimination task. For nonvarying phase motion, observers made large errors in heading judgments. This suggests that instantaneous optic flow is insufficient for heading perception in the presence of rotation. These errors were mostly eliminated when the velocity of phase motion was varied over time to convey the evolving sequence of optic flow fields corresponding to a particular heading. This demonstrates that heading perception in the presence of rotation relies on the time-varying evolution of optic flow. We hypothesize that the visual system accurately computes heading, despite rotation, based on optic acceleration, the temporal derivative of optic flow.},
	pages = {33161--33169},
	number = {52},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {Proc Natl Acad Sci {USA}},
	author = {Burlingham, Charlie S. and Heeger, David J.},
	urldate = {2021-01-26},
	date = {2020-12-29},
	langid = {english},
}

@article{Patla2003,
	title = {How far ahead do we look when required to step on specific locations in the travel path during locomotion?},
	volume = {148},
	issn = {0014-4819, 1432-1106},
	url = {http://link.springer.com/10.1007/s00221-002-1246-y},
	doi = {10.1007/s00221-002-1246-y},
	pages = {133--138},
	number = {1},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Experimental Brain Research},
	author = {Patla, Aftab and Vickers, Joan},
	urldate = {2020-07-18},
	date = {2003-01-01},
}

@article{Li2014,
	title = {Influence of optic flow on the control of heading and target egocentric direction during steering toward a goal},
	volume = {112},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.00697.2013},
	doi = {10.1152/jn.00697.2013},
	abstract = {Although previous studies have shown that people use both optic flow and target egocentric direction to walk or steer toward a goal, it remains in question how enriching the optic flow field affects the control of heading specified by optic flow and the control of target egocentric direction during goal-oriented locomotion. In the current study, we used a control-theoretic approach to separate the control response specific to these two cues in the visual control of steering toward a goal. The results showed that the addition of optic flow information (such as foreground motion and global flow) in the display improved the overall control precision, the amplitude, and the response delay of the control of heading. The amplitude and the response delay of the control of target egocentric direction were, however, not affected. The improvement in the control of heading with enriched optic flow displays was mirrored by an increase in the accuracy of heading perception. The findings provide direct support for the claim that people use the heading specified by optic flow as well as target egocentric direction to walk or steer toward a goal and suggest that the visual system does not internally weigh these two cues for goal-oriented locomotion control.},
	pages = {766--777},
	number = {4},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Li, Li and Niehorster, Diederick C.},
	urldate = {2020-07-20},
	date = {2014-08-15},
	langid = {english},
}

@book{Bradski2011,
	location = {Beijing},
	edition = {1. ed., [Nachdr.]},
	title = {Learning {OpenCV}: computer vision with the {OpenCV} library},
	isbn = {978-0-596-51613-0},
	series = {Software that sees},
	shorttitle = {Learning {OpenCV}},
	pagetotal = {555},
	publisher = {O'Reilly},
	author = {Bradski, Gary R. and Kaehler, Adrian},
	date = {2011},
	note = {{OCLC}: 838472784},
}

@article{einhauser2007,
	title = {Human eye-head co-ordination in natural exploration},
	volume = {18},
	issn = {0954-898X, 1361-6536},
	url = {https://www.tandfonline.com/doi/full/10.1080/09548980701671094},
	doi = {10.1080/09548980701671094},
	abstract = {During natural behavior humans continuously adjust their gaze by moving head and eyes, yielding rich dynamics of the retinal input. Sensory coding models, however, typically assume visual input as smooth or a sequence of static images interleaved by volitional gaze shifts. Are these assumptions valid during free exploration behavior in natural environments? We used an innovative technique to simultaneously record gaze and head movements in humans, who freely explored various environments (forest, train station, apartment). Most movements occur along the cardinal axes, and the predominance of vertical or horizontal movements depends on the environment. Eye and head movements co-occur more frequently than their individual statistics predicts under an independence assumption. The majority of cooccurring movements point in opposite directions, consistent with a gaze-stabilizing role of eye movements. Nevertheless, a substantial fraction of eye movements point in the same direction as co-occurring head movements. Even under the very most conservative assumptions, saccadic eye movements alone cannot account for these synergistic movements. Hence nonsaccadic eye movements that interact synergistically with head movements to adjust gaze cannot be neglected in natural visual input. Natural retinal input is continuously dynamic, and cannot be faithfully modeled as a mere sequence of static frames with interleaved large saccades.},
	pages = {267--297},
	number = {3},
	journaltitle = {Network: Computation in Neural Systems},
	shortjournal = {Network: Computation in Neural Systems},
	author = {Einhäuser, Wolfgang and Schumann, Frank and Bardins, Stanislavs and Bartl, Klaus and Böning, Guido and Schneider, Erich and König, Peter},
	urldate = {2021-01-26},
	date = {2007-01},
	langid = {english},
}

@article{Matthis2013,
	title = {Humans exploit the biomechanics of bipedal gait during visually guided walking over complex terrain},
	volume = {280},
	issn = {0962-8452, 1471-2954},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspb.2013.0700},
	doi = {10.1098/rspb.2013.0700},
	pages = {20130700},
	number = {1762},
	journaltitle = {Proceedings of the Royal Society B: Biological Sciences},
	shortjournal = {Proc. R. Soc. B},
	author = {Matthis, Jonathan Samir and Fajen, Brett R.},
	urldate = {2020-07-22},
	date = {2013-07-07},
	langid = {english},
}

@article{Sunkara2016,
	title = {Joint representation of translational and rotational components of optic flow in parietal cortex},
	volume = {113},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1604818113},
	doi = {10.1073/pnas.1604818113},
	abstract = {Terrestrial navigation naturally involves translations within the horizontal plane and eye rotations about a vertical (yaw) axis to track and fixate targets of interest. Neurons in the macaque ventral intraparietal ({VIP}) area are known to represent heading (the direction of self-translation) from optic flow in a manner that is tolerant to rotational visual cues generated during pursuit eye movements. Previous studies have also reported that eye rotations modulate the response gain of heading tuning curves in {VIP} neurons. We tested the hypothesis that {VIP} neurons simultaneously represent both heading and horizontal (yaw) eye rotation velocity by measuring heading tuning curves for a range of rotational velocities of either real or simulated eye movements. Three findings support the hypothesis of a joint representation. First, we show that rotation velocity selectivity based on gain modulations of visual heading tuning is similar to that measured during pure rotations. Second, gain modulations of heading tuning are similar for self-generated eye rotations and visually simulated rotations, indicating that the representation of rotation velocity in {VIP} is multimodal, driven by both visual and extraretinal signals. Third, we show that roughly one-half of {VIP} neurons jointly represent heading and rotation velocity in a multiplicatively separable manner. These results provide the first evidence, to our knowledge, for a joint representation of translation direction and rotation velocity in parietal cortex and show that rotation velocity can be represented based on visual cues, even in the absence of efference copy signals.},
	pages = {5077--5082},
	number = {18},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {Proc Natl Acad Sci {USA}},
	author = {Sunkara, Adhira and {DeAngelis}, Gregory C. and Angelaki, Dora E.},
	urldate = {2020-07-20},
	date = {2016-05-03},
	langid = {english},
}

@article{calow2007,
	title = {Local statistics of retinal optic flow for self-motion through natural sceneries},
	volume = {18},
	issn = {0954-898X, 1361-6536},
	url = {https://www.tandfonline.com/doi/full/10.1080/09548980701642277},
	doi = {10.1080/09548980701642277},
	abstract = {Image analysis in the visual system is well adapted to the statistics of natural scenes. Investigations of natural image statistics have so far mainly focused on static features. The present study is dedicated to the measurement and the analysis of the statistics of optic flow generated on the retina during locomotion through natural environments. Natural locomotion includes bouncing and swaying of the head and eye movement reflexes that stabilize gaze onto interesting objects in the scene while walking. We investigate the dependencies of the local statistics of optic flow on the depth structure of the natural environment and on the ego-motion parameters. To measure these dependencies we estimate the mutual information between correlated data sets. We analyze the results with respect to the variation of the dependencies over the visual field, since the visual motions in the optic flow vary depending on visual field position. We find that retinal flow direction and retinal speed show only minor statistical interdependencies. Retinal speed is statistically tightly connected to the depth structure of the scene. Retinal flow direction is statistically mostly driven by the relation between the direction of gaze and the direction of ego-motion. These dependencies differ at different visual field positions such that certain areas of the visual field provide more information about ego-motion and other areas provide more information about depth. The statistical properties of natural optic flow may be used to tune the performance of artificial vision systems based on human imitating behavior, and may be useful for analyzing properties of natural vision systems.},
	pages = {343--374},
	number = {4},
	journaltitle = {Network: Computation in Neural Systems},
	shortjournal = {Network: Computation in Neural Systems},
	author = {Calow, Dirk and Lappe, Markus},
	urldate = {2021-01-26},
	date = {2007-01},
	langid = {english},
}

@article{Koenderink1976,
	title = {Local structure of movement parallax of the plane},
	volume = {66},
	issn = {0030-3941},
	url = {https://www.osapublishing.org/abstract.cfm?URI=josa-66-7-717},
	doi = {10.1364/JOSA.66.000717},
	pages = {717},
	number = {7},
	journaltitle = {Journal of the Optical Society of America},
	shortjournal = {J. Opt. Soc. Am.},
	author = {Koenderink, J. J. and van Doorn, A. J.},
	urldate = {2020-07-18},
	date = {1976-07-01},
	langid = {english},
}

@article{royden1997,
	title = {Mathematical analysis of motion-opponent mechanisms used in the determination of heading and depth},
	volume = {14},
	issn = {1084-7529, 1520-8532},
	url = {https://www.osapublishing.org/abstract.cfm?URI=josaa-14-9-2128},
	doi = {10.1364/JOSAA.14.002128},
	pages = {2128},
	number = {9},
	journaltitle = {Journal of the Optical Society of America A},
	shortjournal = {J. Opt. Soc. Am. A},
	author = {Royden, Constance S.},
	urldate = {2021-01-26},
	date = {1997-09-01},
	langid = {english},
}

@article{Reimann2018,
	title = {Neural Control of Balance During Walking},
	volume = {9},
	issn = {1664-042X},
	url = {https://www.frontiersin.org/article/10.3389/fphys.2018.01271/full},
	doi = {10.3389/fphys.2018.01271},
	pages = {1271},
	journaltitle = {Frontiers in Physiology},
	shortjournal = {Front. Physiol.},
	author = {Reimann, Hendrik and Fettrow, Tyler and Thompson, Elizabeth D. and Jeka, John J.},
	urldate = {2020-07-18},
	date = {2018-09-13},
}

@article{Donelan2001,
	title = {Mechanical and metabolic determinants of the preferred step width in human walking},
	volume = {268},
	issn = {0962-8452, 1471-2954},
	url = {https://royalsocietypublishing.org/doi/10.1098/rspb.2001.1761},
	doi = {10.1098/rspb.2001.1761},
	pages = {1985--1992},
	number = {1480},
	journaltitle = {Proceedings of the Royal Society of London. Series B: Biological Sciences},
	shortjournal = {Proc. R. Soc. Lond. B},
	author = {Donelan, Max and Kram, Rodger and Kuo, Arthur D.},
	urldate = {2020-07-18},
	date = {2001-10-07},
	langid = {english},
}

@article{Britten2008,
	title = {Mechanisms of Self-Motion Perception},
	volume = {31},
	issn = {0147-006X, 1545-4126},
	url = {http://www.annualreviews.org/doi/10.1146/annurev.neuro.29.051605.112953},
	doi = {10.1146/annurev.neuro.29.051605.112953},
	pages = {389--410},
	number = {1},
	journaltitle = {Annual Review of Neuroscience},
	shortjournal = {Annu. Rev. Neurosci.},
	author = {Britten, Kenneth H.},
	urldate = {2020-07-18},
	date = {2008-07},
	langid = {english},
}

@article{thart2012,
	title = {Mind the step: complementary effects of an implicit task on eye and head movements in real-life gaze allocation},
	volume = {223},
	issn = {0014-4819, 1432-1106},
	url = {http://link.springer.com/10.1007/s00221-012-3254-x},
	doi = {10.1007/s00221-012-3254-x},
	shorttitle = {Mind the step},
	abstract = {Gaze in real-world scenarios is controlled by a huge variety of parameters, such as stimulus features, instructions or context, all of which have been studied systematically in laboratory studies. It is, however, unclear how these results transfer to real-world situations, when participants are largely unconstrained in their behavior. Here we measure eye and head orientation and gaze in two conditions, in which we ask participants to negotiate paths in a real-world outdoor environment. The implicit task set is varied by using paths of different irregularity: In one condition, the path consists of irregularly placed steps, and in the other condition, a cobbled road is used. With both paths located adjacently, the visual environment (i.e., context and features) for both conditions is virtually identical, as is the instruction. We show that terrain regularity causes differences in head orientation and gaze behavior, speciﬁcally in the vertical direction. Participants direct head and eyes lower when terrain irregularity increases. While head orientation is not affected otherwise, vertical spread of eye-in-head orientation also increases signiﬁcantly for more irregular terrain. This is accompanied by altered patterns of eye movements, which compensate for the lower average gaze to still inspect the visual environment. Our results quantify the importance of implicit task demands for gaze allocation in the real world, and imply qualitatively distinct contributions of eyes and head in gaze allocation. This underlines the care that needs to be taken when inferring real-world behavior from constrained laboratory data.},
	pages = {233--249},
	number = {2},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {’t Hart, Bernard Marius and Einhäuser, Wolfgang},
	urldate = {2021-01-28},
	date = {2012-11},
	langid = {english},
}

@article{perrone1992,
	title = {Model for the computation of self-motion in biological systems},
	volume = {9},
	issn = {1084-7529, 1520-8532},
	url = {https://www.osapublishing.org/abstract.cfm?URI=josaa-9-2-177},
	doi = {10.1364/JOSAA.9.000177},
	pages = {177},
	number = {2},
	journaltitle = {Journal of the Optical Society of America A},
	shortjournal = {J. Opt. Soc. Am. A},
	author = {Perrone, John A.},
	urldate = {2021-01-26},
	date = {1992-02-01},
	langid = {english},
}

@article{McGowan2010,
	title = {Modular control of human walking: Adaptations to altered mechanical demands},
	volume = {43},
	issn = {00219290},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S002192900900582X},
	doi = {10.1016/j.jbiomech.2009.10.009},
	shorttitle = {Modular control of human walking},
	pages = {412--419},
	number = {3},
	journaltitle = {Journal of Biomechanics},
	shortjournal = {Journal of Biomechanics},
	author = {{McGowan}, Craig P. and Neptune, Richard R. and Clark, David J. and Kautz, Steven A.},
	urldate = {2020-07-18},
	date = {2010-02},
	langid = {english},
}

@article{Koenderink1986,
	title = {Optic flow},
	volume = {26},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0042698986900787},
	doi = {10.1016/0042-6989(86)90078-7},
	pages = {161--179},
	number = {1},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Koenderink, Jan J.},
	urldate = {2020-07-18},
	date = {1986-01},
	langid = {english},
}

@article{lappe2000,
	title = {Optic flow and eye movements},
	pages = {29--50},
	journaltitle = {International review of neurobiology},
	author = {Lappe, Markus and Hoffmann, Klaus-Peter},
	date = {2000},
}

@article{Warren2001,
	title = {Optic flow is used to control human walking},
	volume = {4},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/nn0201_213},
	doi = {10.1038/84054},
	pages = {213--216},
	number = {2},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Warren, William H. and Kay, Bruce A. and Zosh, Wendy D. and Duchon, Andrew P. and Sahuc, Stephanie},
	urldate = {2020-07-18},
	date = {2001-02},
	langid = {english},
}

@article{Li2004,
	title = {Path perception during rotation: influence of instructions, depth range, and dot density},
	volume = {44},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0042698904001087},
	doi = {10.1016/j.visres.2004.03.008},
	shorttitle = {Path perception during rotation},
	pages = {1879--1889},
	number = {16},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Li, Li and Warren, William H.},
	urldate = {2020-07-18},
	date = {2004-07},
	langid = {english},
}

@article{li2011,
	title = {Perceiving path from optic flow},
	volume = {11},
	issn = {1534-7362},
	url = {http://jov.arvojournals.org/Article.aspx?doi=10.1167/11.1.22},
	doi = {10.1167/11.1.22},
	pages = {22--22},
	number = {1},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Li, L. and Cheng, J. C. K.},
	urldate = {2021-01-27},
	date = {2011-01-26},
	langid = {english},
}

@article{warren1991,
	title = {On the sufficiency of the velocity field for perception of heading},
	volume = {65},
	issn = {0340-1200, 1432-0770},
	url = {http://link.springer.com/10.1007/BF00216964},
	doi = {10.1007/BF00216964},
	abstract = {All models of self-motion from optical flow assume the instantaneous velocity field as input. We tested this assumption for human observers using random:'dot displays that simulated translational and circular paths of movement by manipulating the lifetime and displacement of individual dots. For translational movement, observers were equally accurate in judging direction of heading from a "velocity field" with a two-frame dot life and a "direction field" in which the magnitudes of displacement were randomized while the radial pattern of directions was preserved, but at chance with a "speed field" in which the directions were randomized, preserving only magnitude. Accuracy declined with increasing noise in vector directions, but remained below 2.6° with a 90° noise envelope. Thus, the visual system uses the radial morphology of vector directions to determine translational heading and can tolerate large amounts of noise in this pattern. For circular movement, observers were equally accurate with a 2-frame "velocity field", 3-frame "acceleration" displays, and 2-frame and 3-frame "direction fields", consistent with the use of the pattern of vector directions to locate the center of rotation. The results indicate that successive independent velocity fields are sufficient for perception of translational and circular heading.},
	pages = {311--320},
	number = {5},
	journaltitle = {Biological Cybernetics},
	shortjournal = {Biol. Cybern.},
	author = {Warren, W. H. and Blackwell, A. W. and Kurtz, K. J. and Hatsopoulos, N. G. and Kalish, M. L.},
	urldate = {2021-01-27},
	date = {1991-09},
	langid = {english},
}

@incollection{Koenderink1984,
	location = {Berlin, Heidelberg},
	title = {Optical Monitoring of Ego-Motion for Movement with Respect to a Plane Surface},
	isbn = {978-3-642-69310-6 978-3-642-69308-3},
	url = {http://link.springer.com/10.1007/978-3-642-69308-3_34},
	pages = {163--166},
	booktitle = {Localization and Orientation in Biology and Engineering},
	publisher = {Springer Berlin Heidelberg},
	author = {Koenderink, J. J. and van Doorn, A. J.},
	editor = {Varjú, D. and Schnitzler, H.-U.},
	urldate = {2020-07-20},
	date = {1984},
	doi = {10.1007/978-3-642-69308-3_34},
	note = {Series Title: Proceedings in Life Sciences},
}

@article{Lappe1999,
	title = {Perception of self-motion from visual flow},
	volume = {3},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661399013649},
	doi = {10.1016/S1364-6613(99)01364-9},
	pages = {329--336},
	number = {9},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Lappe, Markus and Bremmer, Frank and van den Berg, A.V.},
	urldate = {2020-07-18},
	date = {1999-09},
	langid = {english},
}

@article{Paolini2000,
	title = {Responses to Continuously Changing Optic Flow in Area {MST}},
	volume = {84},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.2000.84.2.730},
	doi = {10.1152/jn.2000.84.2.730},
	abstract = {We studied the temporal behavior and tuning properties of medial superior temporal ({MST}) neurons in response to constant flow-field stimulation and continuously changing flow-field stimulation (transitions), which were obtained by morphing one flow field into another. During transitions, the flow fields resembled the motion pattern seen by an observer during changing ego-motion. Our aim was to explore the behavior of {MST} cells in response to changes in the flow-field pattern and to establish whether the responses of {MST} cells are temporally independent or if they are affected by contextual information from preceding stimulation. We first tested whether the responses obtained during transitions were linear with respect to the two stimuli defining the transition. In over half of the transitions, the cell response was nonlinear: the response during the transition could not be predicted by the linear interpolation between the stimulus before and after the transition. Nonlinearities in the responses could arise from a dependence on temporal context or from nonlinearities in the tuning to flow-field patterns. To distinguish between these two hypotheses, we fit the responses during transitions and during continuous stimuli to the predictions of a temporally independent model (temporal-independence test) and we compared the responses during transitions to the responses elicited by inverse transitions (temporal-symmetry test). The effect of temporal context was significant in only 7.2\% and 5.5\% of cells in the temporal-independence test and in the temporal-symmetry test, respectively. Most of the nonlinearities in the cell responses could be accounted for by nonlinearities in the tuning to flow-field stimuli (i.e., the responses to a restricted set of flow fields did not predict the responses to other flow fields). Tuning nonlinearities indicate that a complete characterization of the tuning properties of {MST} neurons cannot be obtained by testing only a small number of flow fields. Because the cells' responses do not depend on temporal context, continuously changing stimulation can be used to characterize the receptive field properties of cells more efficiently than constant stimulation. Temporal independence in the responses to transitions indicates that {MST} cells do not code for second-order temporal properties of flow-field stimuli, i.e., for changes in the flow field through time that can be construed as paths through the environment. Information about ego-motion three-dimensional paths through the environment may either be processed at the population level in {MST} or in other cortical areas.},
	pages = {730--743},
	number = {2},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Paolini, Monica and Distler, Claudia and Bremmer, Frank and Lappe, Markus and Hoffmann, Klaus-Peter},
	urldate = {2020-07-18},
	date = {2000-08-01},
	langid = {english},
}

@article{Duffy1991,
	title = {Sensitivity of {MST} neurons to optic flow stimuli. I. A continuum of response selectivity to large-field stimuli},
	volume = {65},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.1991.65.6.1329},
	doi = {10.1152/jn.1991.65.6.1329},
	abstract = {1. Neurons in the dorsomedial region of the medial superior temporal area ({MSTd}) have large receptive fields that include the fovea, are directionally selective for moving visual stimuli, prefer the motion of large fields to small spots, and respond to rotating and expanding patterns of motion as well as frontal parallel planar motion. These characteristics suggested that these neurons might contribute to the analysis of the large-field optic flow stimulation generated as an observer moves through the visual environment. 2. We tested the response of {MSTd} neurons in two awake monkeys by systematically presenting a set of translational and rotational stimuli to each neuron. These 100 X 100 degrees stimuli were the motion components from which all optic flow fields are derived. 3. In 220 single neurons we found 23\% that responded primarily to one component of motion (planar, circular, or radial), 34\% that responded to two components (planocircular or planoradial, but never circuloradial), and 29\% that responded to all three components. 4. The number of stimulus components to which a neuron responded was unrelated to the size or eccentricity of its receptive field. 5. Triple-, double-, and single-component neurons varied widely in the strength of their responses to the preferred components. Grouping these neurons together revealed that they did not form discrete classes but rather a continuum of response selectivity. 6. This continuum was apparent in other response characteristics. Direction selectivity was weakest in triple-component neurons, strongest in single-component neurons. Significant inhibitory responses were less frequent in triple-component neurons than in single-component neurons. 7. There was some indication that the neurons of similar component classes occupied adjacent regions within {MSTd}, but all combinations of component and direction selectivity were occasionally found in immediate juxtaposition. 8. Experiments on a subset of neurons showed that the speed of motion, the dot density, and the number of different speed planes in the display had little influence on these responses. 9. We conclude that the selective responses of many {MSTd} neurons to the rotational and translational components of optic flow make these neurons reasonable candidates for contributing to the analysis of optic flow fields.},
	pages = {1329--1345},
	number = {6},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Duffy, C. J. and Wurtz, R. H.},
	urldate = {2020-07-18},
	date = {1991-06-01},
	langid = {english},
}

@article{Wann2000,
	title = {Steering with or without the flow: is the retrieval of heading necessary?},
	volume = {4},
	issn = {13646613},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S1364661300015138},
	doi = {10.1016/S1364-6613(00)01513-8},
	shorttitle = {Steering with or without the flow},
	pages = {319--324},
	number = {8},
	journaltitle = {Trends in Cognitive Sciences},
	shortjournal = {Trends in Cognitive Sciences},
	author = {Wann, John and Land, Michael},
	urldate = {2020-07-18},
	date = {2000-08},
	langid = {english},
}

@article{Dietrich2019,
	title = {Strategies for Gaze Stabilization Critically Depend on Locomotor Speed},
	volume = {408},
	issn = {03064522},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0306452219300454},
	doi = {10.1016/j.neuroscience.2019.01.025},
	pages = {418--429},
	journaltitle = {Neuroscience},
	shortjournal = {Neuroscience},
	author = {Dietrich, H. and Wuehr, M.},
	urldate = {2020-07-18},
	date = {2019-06},
	langid = {english},
}

@article{heeger1992,
	title = {Subspace methods for recovering rigid motion I: Algorithm and implementation},
	volume = {7},
	issn = {0920-5691, 1573-1405},
	url = {http://link.springer.com/10.1007/BF00128130},
	doi = {10.1007/BF00128130},
	shorttitle = {Subspace methods for recovering rigid motion I},
	abstract = {As an observer moves and explores the environment, the visual stimulation in his/her eye is constantly changing. Somehow he/she is able to perceive the spatial layout of the scene, and to discern his/her movement through space. Computational vision researchers have been trying to solve this problem for a number of years with only limited success. It is a difficult problem to solve because the optical flow field is nonlinearly related to the 3D motion and depth parameters.},
	pages = {95--117},
	number = {2},
	journaltitle = {International Journal of Computer Vision},
	shortjournal = {Int J Comput Vision},
	author = {Heeger, David J. and Jepson, Allan D.},
	urldate = {2021-01-26},
	date = {1992-01},
	langid = {english},
}

@article{Nakamura2016,
	title = {Relative Visual Oscillation Can Facilitate Visually Induced Self-Motion Perception},
	volume = {7},
	issn = {2041-6695, 2041-6695},
	url = {http://journals.sagepub.com/doi/full/10.1177/2041669516661903},
	doi = {10.1177/2041669516661903},
	abstract = {Adding simulated viewpoint jitter or oscillation to displays enhances visually induced illusions of self-motion (vection). The cause of this enhancement is yet to be fully understood. Here, we conducted psychophysical experiments to investigate the effects of different types of simulated oscillation on vertical vection. Observers viewed horizontally oscillating and nonoscillating optic flow fields simulating downward self-motion through an aperture. The aperture was visually simulated to be nearer to the observer and was stationary or oscillating in-phase or counterphase to the direction of background horizontal oscillations of optic flow. Results showed that vection strength was modulated by the oscillation of the aperture relative to the background optic flow. Vertical vection strength increased as the relative oscillatory horizontal motion between the flow and the aperture increased. However, such increases in vection were only generated when the added oscillations were orthogonal to the principal direction of the optic flow pattern, and not when they occurred in the same direction. The oscillation effects observed in this investigation could not be explained by motion adaptation or different (motion parallax based) effects on depth perception. Instead, these results suggest that the oscillation advantage for vection depends on relative visual motion.},
	pages = {204166951666190},
	number = {4},
	journaltitle = {i-Perception},
	shortjournal = {i-Perception},
	author = {Nakamura, Shinji and Palmisano, Stephen and Kim, Juno},
	urldate = {2020-07-20},
	date = {2016-07},
	langid = {english},
}

@article{walls1962,
	title = {The evolutionary history of eye movements},
	volume = {2},
	issn = {00426989},
	url = {https://linkinghub.elsevier.com/retrieve/pii/0042698962900640},
	doi = {10.1016/0042-6989(62)90064-0},
	pages = {69--80},
	number = {1},
	journaltitle = {Vision Research},
	shortjournal = {Vision Research},
	author = {Walls, G.L.},
	urldate = {2021-01-27},
	date = {1962-01},
	langid = {english},
}

@article{Longuet-Higgins1980,
	title = {The interpretation of a moving retinal image},
	volume = {208},
	doi = {https://doi.org/10.1098/rspb.1980.0057},
	pages = {13},
	journaltitle = {Proceedings of the Royal Society B: Biological Sciences},
	author = {Longuet-Higgins, Hugh Christopher and Prazdny, K},
	date = {1980},
	langid = {english},
}

@book{Gibson1950,
	location = {Westport, Conn},
	title = {The perception of the visual world},
	isbn = {978-0-8371-7836-3},
	pagetotal = {235},
	publisher = {Greenwood Press},
	author = {Gibson, James J.},
	date = {1950},
	keywords = {Visual perception},
}

@article{Roth2016,
	title = {Thalamic nuclei convey diverse contextual information to layer 1 of visual cortex},
	volume = {19},
	issn = {1097-6256, 1546-1726},
	url = {http://www.nature.com/articles/nn.4197},
	doi = {10.1038/nn.4197},
	pages = {299--307},
	number = {2},
	journaltitle = {Nature Neuroscience},
	shortjournal = {Nat Neurosci},
	author = {Roth, Morgane M and Dahmen, Johannes C and Muir, Dylan R and Imhof, Fabia and Martini, Francisco J and Hofer, Sonja B},
	urldate = {2020-07-18},
	date = {2016-02},
	langid = {english},
}

@article{Matthis2017,
	title = {The critical phase for visual control of human walking over complex terrain},
	volume = {114},
	issn = {0027-8424, 1091-6490},
	url = {http://www.pnas.org/lookup/doi/10.1073/pnas.1611699114},
	doi = {10.1073/pnas.1611699114},
	abstract = {To walk efficiently over complex terrain, humans must use vision to tailor their gait to the upcoming ground surface without interfering with the exploitation of passive mechanical forces. We propose that walkers use visual information to initialize the mechanical state of the body before the beginning of each step so the resulting ballistic trajectory of the walker’s center-of-mass will facilitate stepping on target footholds. Using a precision stepping task and synchronizing target visibility to the gait cycle, we empirically validated two predictions derived from this strategy: (1) Walkers must have information about upcoming footholds during the second half of the preceding step, and (2) foot placement is guided by information about the position of the target foothold relative to the preceding base of support. We conclude that active and passive modes of control work synergistically to allow walkers to negotiate complex terrain with efficiency, stability, and precision.},
	pages = {E6720--E6729},
	number = {32},
	journaltitle = {Proceedings of the National Academy of Sciences},
	shortjournal = {Proc Natl Acad Sci {USA}},
	author = {Matthis, Jonathan Samir and Barton, Sean L. and Fajen, Brett R.},
	urldate = {2020-07-18},
	date = {2017-08-08},
	langid = {english},
}

@book{Gibson1979,
	location = {New York, London},
	title = {The ecological approach to visual perception},
	isbn = {978-1-84872-578-2},
	pagetotal = {315},
	publisher = {Psychology Press},
	author = {Gibson, James J.},
	date = {1979},
	note = {{OCLC}: 962481298},
}

@incollection{Land2018,
	location = {Cham},
	title = {The Evolution of Gaze Shifting Eye Movements},
	volume = {41},
	isbn = {978-3-030-31025-7 978-3-030-31026-4},
	url = {http://link.springer.com/10.1007/7854_2018_60},
	pages = {3--11},
	booktitle = {Processes of Visuospatial Attention and Working Memory},
	publisher = {Springer International Publishing},
	author = {Land, Michael F.},
	editor = {Hodgson, Timothy},
	urldate = {2020-07-18},
	date = {2018},
	langid = {english},
	doi = {10.1007/7854_2018_60},
	note = {Series Title: Current Topics in Behavioral Neurosciences},
}

@article{Royden1992,
	title = {The perception of heading during eye movements},
	volume = {360},
	issn = {0028-0836, 1476-4687},
	url = {http://www.nature.com/articles/360583a0},
	doi = {10.1038/360583a0},
	pages = {583--585},
	number = {6404},
	journaltitle = {Nature},
	shortjournal = {Nature},
	author = {Royden, Constance S. and Banks, Martin S. and Crowell, James A.},
	urldate = {2020-07-18},
	date = {1992-12},
	langid = {english},
}

@article{bossard2016,
	title = {Viewpoint oscillation improves the perception of distance travelled based on optic flow},
	volume = {16},
	issn = {1534-7362},
	url = {http://jov.arvojournals.org/article.aspx?doi=10.1167/16.15.4},
	doi = {10.1167/16.15.4},
	pages = {4},
	number = {15},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Bossard, Martin and Goulon, Cédric and Mestre, Daniel R.},
	urldate = {2021-01-27},
	date = {2016-12-05},
	langid = {english},
}

@article{bossard2020,
	title = {Viewpoint oscillation improves the perception of distance travelled in static observers but not during treadmill walking},
	volume = {238},
	issn = {0014-4819, 1432-1106},
	url = {http://link.springer.com/10.1007/s00221-020-05786-y},
	doi = {10.1007/s00221-020-05786-y},
	abstract = {Optic flow has been found to be a significant cue for static observers’ perception of distance travelled. In previous research conducted in a large-scale immersive display ({CAVE}), adding viewpoint oscillations to a radial optic flow simulating forward self-motion was found to modulate this perception. In the present two experiments, we investigated (1) whether the improved distance travelled perceptions observed with an oscillating viewpoint in a {CAVE} were also obtained when the subjects were wearing a head mounted display ({HMD}, an Oculus Rift) and (2) whether the absence of viewpoint oscillations during treadmill walking was liable to affect the subjects’ perception of self-motion. In Experiment 1, static observers performed a distance travelled estimation task while facing either a purely linear visual simulation of self-motion (in depth) or the same flow in addition to viewpoint oscillations based on the subjects’ own head oscillations previously recorded during treadmill walking. Results show that the benefits of viewpoint oscillations observed in a {CAVE} persisted when the participants were wearing an {HMD}. In Experiment 2, participants had to carry out the same task while walking on a treadmill under two different visual conditions simulating self-motion in depth: the one with and the other without the visual consequences of their head translations. Results showed that viewpoint oscillations did not improve the accuracy of subjects’ distance travelled estimations. A comparison between the two experiments showed that adding internal dynamic information about actual self-motion to visual information did not allow participants better estimates.},
	pages = {1073--1083},
	number = {4},
	journaltitle = {Experimental Brain Research},
	shortjournal = {Exp Brain Res},
	author = {Bossard, Martin and Goulon, Cédric and Mestre, Daniel},
	urldate = {2021-01-27},
	date = {2020-04},
	langid = {english},
}

@article{perrone2018,
	title = {Visual–vestibular estimation of the body's curvilinear motion through the world: A computational model},
	volume = {18},
	issn = {1534-7362},
	url = {http://jov.arvojournals.org/article.aspx?doi=10.1167/18.4.1},
	doi = {10.1167/18.4.1},
	shorttitle = {Visual–vestibular estimation of the body's curvilinear motion through the world},
	pages = {1},
	number = {4},
	journaltitle = {Journal of Vision},
	shortjournal = {Journal of Vision},
	author = {Perrone, John A.},
	urldate = {2021-01-26},
	date = {2018-04-04},
	langid = {english},
}

@inproceedings{Rogers1999,
	title = {The role of (i) perceived direction and (ii) optic flow in the control of locomotion and for estimating the point of impact},
	volume = {40},
	pages = {S764--S764},
	booktitle = {{INVESTIGATIVE} {OPHTHALMOLOGY} \& {VISUAL} {SCIENCE}},
	author = {Rogers, Brian J and Dalton, Catherine},
	date = {1999},
	note = {Number: 4
tex.organization: {ASSOC} {RESEARCH} {VISION} {OPHTHALMOLOGY} {INC} 9650 {ROCKVILLE} {PIKE}, {BETHESDA}, {MD} …},
}

@article{Kuo2007,
	title = {The six determinants of gait and the inverted pendulum analogy: A dynamic walking perspective},
	volume = {26},
	issn = {01679457},
	url = {https://linkinghub.elsevier.com/retrieve/pii/S0167945707000309},
	doi = {10.1016/j.humov.2007.04.003},
	shorttitle = {The six determinants of gait and the inverted pendulum analogy},
	pages = {617--656},
	number = {4},
	journaltitle = {Human Movement Science},
	shortjournal = {Human Movement Science},
	author = {Kuo, Arthur D.},
	urldate = {2020-07-18},
	date = {2007-08},
	langid = {english},
}

@article{Matthis2014,
	title = {Visual control of foot placement when walking over complex terrain.},
	volume = {40},
	issn = {1939-1277, 0096-1523},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/a0033101},
	doi = {10.1037/a0033101},
	abstract = {The aim of this study was to investigate the role of visual information in the control of walking over complex terrain with irregularly spaced obstacles. We developed an experimental paradigm to measure how far along the future path people need to see in order to maintain forward progress and avoid stepping on obstacles. Participants walked over an array of randomly distributed virtual obstacles that were projected onto the floor by an {LCD} projector while their movements were tracked by a full-body motion capture system. Walking behavior in a full-vision control condition was compared with behavior in a number of other visibility conditions in which obstacles did not appear until they fell within a window of visibility centered on the moving observer. Collisions with obstacles were more frequent and, for some participants, walking speed was slower when the visibility window constrained vision to less than two step lengths ahead. When window sizes were greater than two step lengths, the frequency of collisions and walking speed were weakly affected or unaffected. We conclude that visual information from at least two step lengths ahead is needed to guide foot placement when walking over complex terrain. When placed in the context of recent research on the biomechanics of walking, the findings suggest that two step lengths of visual information may be needed because it allows walkers to exploit the passive mechanical forces inherent to bipedal locomotion, thereby avoiding obstacles while maximizing energetic efficiency.},
	pages = {106--115},
	number = {1},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	shortjournal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Matthis, Jonathan S. and Fajen, Brett R.},
	urldate = {2020-07-22},
	date = {2014-02},
	langid = {english},
}

@article{barton2017,
	title = {Visual regulation of gait: Zeroing in on a solution to the complex terrain problem.},
	volume = {43},
	issn = {1939-1277, 0096-1523},
	url = {http://doi.apa.org/getdoi.cfm?doi=10.1037/xhp0000435},
	doi = {10.1037/xhp0000435},
	shorttitle = {Visual regulation of gait},
	pages = {1773--1790},
	number = {10},
	journaltitle = {Journal of Experimental Psychology: Human Perception and Performance},
	shortjournal = {Journal of Experimental Psychology: Human Perception and Performance},
	author = {Barton, Sean L. and Matthis, Jonathan S. and Fajen, Brett R.},
	urldate = {2021-01-26},
	date = {2017-10},
	langid = {english},
}

@article{kaminiarz2014,
	title = {Visual selectivity for heading in the macaque ventral intraparietal area},
	volume = {112},
	issn = {0022-3077, 1522-1598},
	url = {https://www.physiology.org/doi/10.1152/jn.00410.2014},
	doi = {10.1152/jn.00410.2014},
	abstract = {The patterns of optic flow seen during self-motion can be used to determine the direction of one's own heading. Tracking eye movements which typically occur during everyday life alter this task since they add further retinal image motion and (predictably) distort the retinal flow pattern. Humans employ both visual and nonvisual (extraretinal) information to solve a heading task in such case. Likewise, it has been shown that neurons in the monkey medial superior temporal area (area {MST}) use both signals during the processing of self-motion information. In this article we report that neurons in the macaque ventral intraparietal area (area {VIP}) use visual information derived from the distorted flow patterns to encode heading during (simulated) eye movements. We recorded responses of {VIP} neurons to simple radial flow fields and to distorted flow fields that simulated self-motion plus eye movements. In 59\% of the cases, cell responses compensated for the distortion and kept the same heading selectivity irrespective of different simulated eye movements. In addition, response modulations during real compared with simulated eye movements were smaller, being consistent with reafferent signaling involved in the processing of the visual consequences of eye movements in area {VIP}. We conclude that the motion selectivities found in area {VIP}, like those in area {MST}, provide a way to successfully analyze and use flow fields during self-motion and simultaneous tracking movements.},
	pages = {2470--2480},
	number = {10},
	journaltitle = {Journal of Neurophysiology},
	shortjournal = {Journal of Neurophysiology},
	author = {Kaminiarz, Andre and Schlack, Anja and Hoffmann, Klaus-Peter and Lappe, Markus and Bremmer, Frank},
	urldate = {2021-01-19},
	date = {2014-11-15},
	langid = {english},
}

@article{cutting1992,
	title = {Wayfinding on Foot From Information in Retinal, Not Optical, Flow},
	pages = {32},
	journaltitle = {Journal of Experimental Psychology: General},
	author = {Cutting, James E and Springer, Ken},
	date = {1992},
	langid = {english},
}
