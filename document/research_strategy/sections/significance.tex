Walking through complex natural environments requires the robust
integration of our visual and motor systems. The visual and motor
components of visually-guided walking, visual search and the
biomechanics of bipedal locomotion, have been studied extensively, but
largely in isolation.

\begin{itemize}
\item
  Recent work (that we have been heavily involved in) takes important
  first steps to integrated understanding of the visuomotor control of
  walking.
\end{itemize}

Visual search

Gap 1. how visual processing supports human movement in the real-world

Testing in real life. the sequence of events that happen in the real
world.

The large datasets that are being generated only have eye movements and
world content: ego 4d and other long list of stuff. An old idea in
cognitive science and visual perception that has gained traction in the
ML community via reinforcement learning approaches is that the ability
to take action and adjust your own input influences learning. We need
datasets with stored actions to make this happen\ldots{}

Gap 2. The tech to actually study this doesn't exist. We're uniquely
positioned to study it.

New technology is a gap -- it's still a lot of work. We're going

\begin{itemize}
\item
  Established the general patterns of visuomotor control, but now we
  need to:

  \begin{itemize}
  \item
    1. Leverage improved processes for collecting integrated visuomotor
    datasets to collect more precise, expanded datasets.
  \item
    2. Develop laboratory protocols that allow for the
  \end{itemize}
\end{itemize}
that allow for the