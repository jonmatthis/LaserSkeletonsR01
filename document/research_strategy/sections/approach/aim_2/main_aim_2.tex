
\noindent\underline{\textbf{Rationale:}}

\noindent\underline{\textbf{Research Design:}}

iii. \emph{What makes a ``good'' foothold?} Foothold locations are
determined by a variety of factors: getting to a location, minimizing the energetic costs of walking, avoiding paths that change in height or direction, stability and/or ``flatness'' of the ground. Basically, you want to get from point A to B, but without getting too tired or stepping on wobbly rocks. How do walkers trade off these different costs? Our preliminary work on this question demonstrates that walkers select paths that are flatter, electing to take more circuitous paths to keep the change in height across steps lower [CITE]. The photogrammetry pipeline was used to build depth maps of the walking terrain and generate viable alternative routes to compare with those chosen by walkers. Additional analyses (using a CNN trained on depth maps) demonstrated that subject-perspective depth maps contain sufficient information to classify foothold locations.

In order to address this question more broadly, we will: 1. Repeat the path height analyses, examining the impact of path height and depth content on foothold selection in our larger dataset, establishing the level of individual variability in the tradeoff between changing path height and more circuitous routes 2. Analyze the role of texture cues (i.e., monocular features) available in the scene on foothold selection. We will train classifiers for foothold and non-foothold locations, using both standard visual processing models (e.g., Portilla-Simoncelli,... 1-2 others) and pre-trained ML models (e.g., VGG, ResNet, ViT) generate an embedding of the visual input. The variety of approaches, combined with the filtering out of different types of information (spatial frequency, orientation, regions of interest) will allow us to determine what types of information can be used by such a classifier to distinguish a good foothold location. 3. Develop a binocular RNN model that identifies good foothold locations in a visual scene, learning from the human data. We will examine how generalizeable models are across individuals. We will look at the role of monocular vs binocular cues by building comparable monocular and perspective depth map versions of the RNN model. Taken together these analyses will build a better understanding of what makes a good foothold and how visual processing supports the selection of good footholds.