\begin{itemize}


\item
  Integrated visuomotor datasets from humans walking in real-world
  environments.

  \begin{itemize}
  \item
    Extended to include new technologies: photogrammetry methods which
    extracts the scene structure and location of the camera (i.e. the
    head) in space, improving the accuracy of body/gaze calibration.
  \item
    A dataset that is one order of magnitude larger than the existing
    datasets
  \item
    Re-usable data collection pipelines
  \end{itemize}
\item
  augmented reality ground plane

  \begin{itemize}
  \item
    Body + eye movement contingent
  \item
    Complementary to outdoor data collection
  \item
    Generation of complex scenes that are more precisely controlled.
  \item
    Approach will allow us to isolate/test real-world observations
  \end{itemize}
\end{itemize}

Text from Trent's F32:

\begin{itemize}
\item
  Previous laboratory investigations into the visual control of foot
  placement have been greatly restricted by the length of the walkable
  space17--19, where only a few steps are recordable in a given trial
  and (in some cases) no feedback is provided to the participant to tell
  them if their foot placement was successful. Additionally, some of the
  best work investigating the visual control of foot placement took
  place at a time where there was a technological inability to measure
  precise eye movements in relation to the gait cycle in real time.
  Here, we develop our new experimental paradigm using an indoor, 14m
  long (3m wide) projector-based Augmented Reality (AR) groundplane
  (\emph{Fig. 2}, \emph{Fig. 3}), which participants will actively walk
  across, enabling us to measure \textasciitilde25 footsteps made in a
  given trial. We will measure participant eye movements with a mobile,
  binocular eye tracker (Pupil Labs), as well as their full body
  kinematics and position tracking using maker based motion capture
  (Qualisys). By combining new technologies with a much larger
  laboratory space (as well as an improved capacity to measure
  visuo-locomotor in natural, outdoor terrains), we provide the first
  experimental designs which will be sufficient to understand the
  influence of biomechanical constraint in visual search.
\end{itemize}
