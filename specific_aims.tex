
\section*{Specific Aims}

% Following this sort of format: https://www.biosciencewriters.com/NIH-Grant-Applications-The-Anatomy-of-a-Specific-Aims-Page.aspx

% First Paragraph: 
Vision provides crucial information for successfully moving through the environments of daily life.  There is a rich and growing body of literature that describes vision and visual perception in response to dynamic and realistic environments [CITE], as well as the details of the biomechanics of walking in natural environments [CITE].  However, the vast majority of experiments investigating the sensorimotor processes underpinning the visually-guided walking are conducted in isolation, focusing primarily on visual perception or motor function [CITE].  As a result, there is a lack of data to support the development of a normative description of the sensorimotor processes involved in walking.  This significantly hinders the development of models of the cognitive planning and visual information gathering processes that integrate the details of visual processing AND the bimoechanics of human movement. Understanding these basic sensorimotor processes is critical to human health as we age, as there is considerable evidence that visual impairment and other changes associated with aging put individuals at a high risk for falls.

The overarching goal of this proposal is to \textbf{develop an integrated model of the visuomotor processes that support movement through real-world environments}. It will provide a detailed and integrated account of the visual information gathering and cognitive/motor planning processes that support walking.  We will take into consideration the role of divided attention and the way that it shapes the coordination of gaze and gait by limiting visual information gathering and cognitive processing.  This work will be informed by the collection of an \textbf{integrated visuomotor dataset (eye tracking and full-body movement through real-world environments)} and a series of controlled-laboratory experiments with protocols designed to mimic the visually-guided walking observed in the natural environment.  These complementary approaches will enable the observation of real-world behavior, while still providing precise laboratory measurements to test specific hypotheses related to the \textbf{dynamics of visual information-gathering and motor planning}.  

We are uniquely positioned tackle this set of scientific questions, having developed both environment- and laboratory-based data collection techniques that produce integrated visuomotor datasets for full-body movement.  The fields of vision science, neuroscience, and biomechanics are at a critical junction as advances in machine learning increase the capacity for processing and analyzing big multi-modal data.  However, the success of such efforts is dependent on the content and quality of the data that exist.  Our proposed work will result in a high-quality, open-source, visuomotor dataset.  Furthermore, each aim includes planned technical deliverables.  These open-source solutions will lower the barrier for creating integrated visuomotor datasets. Because of the rarity of such datasets for full-body movement and the current difficulty of producing them, these technical deliverables are a central contribution of the proposal, but one that is deeply intertwined with the scientific goals.


\begin{description}
	\item[SA1: Information gathering and motor planning during full-body movement through real-world environments.]{There is a lack of normative baseline data on how individuals use their vision to actively select the information that guides walking through complex environments. Our approach will be to collect an integrated visuomotor dataset (including body movements, eye movements and the environment) in 50 adults with typical vision and motor function. We will analyze motor planning strategies, assess how the moment-to-moment instability of gait impacts gaze behavior, and identify adaptive gaze patterns. More generally, we will model the coordination of gaze/gait during visually-guided walking, establishing typical gaze patterns in the context of the motor behavior. \textit{SA1} will provide a comprehensive description of the sensorimotor processes that underlie visually-guided walking. \textit{Technical Deliverables (SA1):} comprehensive visuomotor dataset; open-source documentation of the hardware infrastructure for collecting low-cost, high-quality integrated visuomotor data; open-source software processing pipeline for integrating multi-modal dataset into the same spatial reference frame.}

 
% \begin{description}
% 	\item[SA1: Laser Skeletons]{Characterize the coordination of gaze and gait during walking in complex terrains.}
% 	\item[Rationale:] {There is a lack of normative baseline data on how individuals actively use their visual systems to select information for guiding gross sensory motor movements, such as walking, in complex environments. Establishing a better understanding of gaze patterns and motor planning during walking will provide valuable insights into visual processing and movement coordination.}
% \item[Approach:]{We will collect data from 50 adults with typical vision to comprehensively describe their eye movements during walking in various terrains. We will analyze motor planning strategies, changes in gaze behavior during instability, and identify advantageous gaze patterns during moments of instability.}
% \item[Technical Deliverables:]{ A comprehensive dataset of eye movement patterns in adults. Detailed analyses of motor planning strategies and gaze behavior during walking.  Data/Analysis infrastructure that support the re-use of the dataset by other groups. Open source data collection infrastructure that supports the collection of new datasets by other groups.}
% \end{description}

    \item[SA2: Testing the spatial and temporal dynamics of visual information gathering and motor planning.] {We have developed a body- and gaze-contingent augmented reality ground plane (3m x 10m) for the presentation of arbitrary 2D walking paths. Preliminary results show that the manipulation of foothold sparsity results in modulation of gaze/gait behavior that mimics the changes due to different terrain complexity observed in natural environments. We will manipulate the availability of visual information based on current body position and gaze location to identify the role of temporal dynamics and peripheral processing in the visual information gathering that supports walking.  \textit{SA2} will identify when and where in the visual field the critical information for foothold selection during walking occurs. \textit{Technical Deliverables (SA2):} open source hardware specifications for "augmented reality ground-plane"; open-source software processing pipeline for integrating laboratory-based multi-modal data into the same spatial reference frame}

    % saving this for later...
    % \textit{Technical deliverables:} detailed documentation of the hardware infrastructure and laboratory protocols the augmented reality ground-plane; integration of the laboratory-based data collection techniques with the software processing pipeline described in SA1. }

%     \begin{description}
% 	\item[Aim 2: Augmented Reality Ground Plane] {Develop laboratory protocols using an augmented reality ground plane to disentangle motor planning strategies and visual information processing strategies observed during walking in natural environments.  }

% \item[]{Rationale: Observational data from natural environments informs this set of laboratory experiments, allowing for controlled examination of visual information and its influence on motor planning and gaze-gait coordination. This approach will enable a deeper understanding of the underlying mechanisms and strategies involved in walking.}
% \item[]{ Approach: We will use an augmented reality ground plane to tightly control what visual information is available and when it is available. By controlling the available visual information, we will test hypotheses derived from the observational data regarding motor planning and gaze-gait coordination.}
% \item[] {Technical Deliverables: A set of laboratory protocols utilizing augmented reality technology, designed to systematically control and manipulate visual information during walking experiments. These protocols will enable researchers to investigate the interaction between visual processing and motor planning in a controlled setting.}
% \end{description}

    \item[SA3: Impact of Divided on Attention on the visuomotor control of walking.] {The data collection effort described in SA1 will include a divided attention condition. Participants will be asked to walk while talking to an experimenter and/or completing tasks on their phone.  Prior work across gait and postural control studies demonstrates that there is a cost to divided attention [CITE]. We will measure the impact of divided attention on the coordination of gaze/gait during full-body movement through real-world environments. \textit{SA3} will provide insight into how visual information gathering and motor planning resources are allocated when individuals are simultaneously engaged in two tasks. \textit{Technical Deliverables (SA3): divided attention extension to comprehensive visuomotor dataset (see SA1)}}.

% \begin{description}
% 	\item[Aim 3: Divided Attention] {Examine the impact of divided attention on the coordination of gaze and gait.}
 
% 	\item{Rationale: In everyday life, people often engage in multiple activities simultaneously while navigating their environment, making it important to understand how divided attention affects gaze and gait coordination. Furthermore, age-related changes in multitasking abilities may impact gaze-gait coordination and warrant investigation.}
 
%     \item{Approach: We will simultaneously collect this data in Aim 1, with participants walking across complex terrains while engaging in divided attention tasks such as playing on their phone or talking to a friend. We will observe and analyze gaze patterns and gait coordination under these divided attention conditions.}
    
%     \item{Technical Deliverables: A comprehensive dataset on gaze and gait coordination during divided attention tasks, providing insights into the impact of multitasking on walking performance and the safe navigation of complex environments.}


\end{description}

% You could potentially end with a summary if you feel like it.
% The expected outcome of the proposed research is a characterization of ... The health relevance of the research resides in understanding ..
